{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_scor\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "import joblib\n",
        "\n",
        "# Load data\n",
        "try:\n",
        "    Data = pd.read_csv('data.csv',on_bad_lines='skip')\n",
        "except Exception as e:\n",
        "    print(f\"Error loading the data: {e}\")\n",
        "\n",
        "\n",
        "# Extract features and labels\n",
        "Passwords = Data['password']\n",
        "Labels = Data['strength']\n",
        "\n",
        "Passwords = Passwords.fillna('')\n",
        "\n",
        "Passwords = Passwords.astype(str)\n",
        "\n",
        "# Vectorize using TF-IDF with character n-grams\n",
        "Vectorize = TfidfVectorizer(analyzer='char', ngram_range=(1,3), max_features=5000)  # Limit the feature space\n",
        "\n",
        "\n",
        "try:\n",
        "    Password_Vector = Vectorize.fit_transform(Passwords)\n",
        "except Exception as e:\n",
        "    print(f\"Vectorization failed: {e}\")\n",
        "\n",
        "joblib.dump(Vectorize, 'Vectorize.joblib')\n",
        "# Convert sparse matrix to array for compatibility\n",
        "Input_Dataset = Password_Vector.toarray()\n",
        "Output_Dataset = Labels\n",
        "\n",
        "\n",
        "# Split into train/test sets\n",
        "Input_Train, Input_Test, Output_Train, Output_Test = train_test_split(\n",
        "    Input_Dataset, Output_Dataset, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# Create and train the Logistic Regression model\n",
        "Model = LogisticRegression(max_iter=200, solver='liblinear')  # Added solver and iteration limit\n",
        "Model.fit(Input_Train, Output_Train)\n",
        "joblib.dump(Model, 'Password.joblib')\n",
        "# Test predictions\n",
        "Prediction = Model.predict(Input_Test)\n",
        "print(Prediction)\n",
        "# Evaluate performance\n",
        "Accuracy = accuracy_score(Output_Test, Prediction)\n",
        "\n",
        "# Output the results\n",
        "print(f\"Accuracy: {Accuracy}\")\n"
      ],
      "metadata": {
        "id": "D61jW00LnWdF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# Load the saved model and vectorizer\n",
        "Model = joblib.load('Password_RF.joblib')\n",
        "Vectorize = joblib.load('Vectorize_RF.joblib')\n",
        "\n",
        "\n",
        "\n",
        "# Predict using the loaded model\n",
        "for _ in range(5):\n",
        "  try:\n",
        "      Password = input(\"Enter a password to predict its strength: \")\n",
        "      Password_Vector = Vectorize.transform([Password]).toarray()\n",
        "\n",
        "      P = Model.predict(Password_Vector)\n",
        "      print(\"Predictions:\")\n",
        "      print(P[0])\n",
        "  except ValueError as e:\n",
        "      print(f\"Error during prediction: {e}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "id": "MD9sxVT_rOFd",
        "outputId": "2be95408-d8a5-4fe9-ed20-171c081c7cef"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter a password to predict its strength: E$%36Ghsj)03\n",
            "Predictions:\n",
            "1\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "Interrupted by user",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-68486582a882>\u001b[0m in \u001b[0;36m<cell line: 11>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m       \u001b[0mPassword\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Enter a password to predict its strength: \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m       \u001b[0mPassword_Vector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVectorize\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mPassword\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    849\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m             )\n\u001b[0;32m--> 851\u001b[0;31m         return self._input_request(str(prompt),\n\u001b[0m\u001b[1;32m    852\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    853\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
          ]
        }
      ]
    },
    {
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "import joblib\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "chunksize = 10000\n",
        "model = LogisticRegression(max_iter=200, solver='liblinear')\n",
        "\n",
        "Vectorize = TfidfVectorizer(analyzer='char', ngram_range=(1,3), max_features=5000)\n",
        "\n",
        "for chunk in pd.read_csv('data.csv', chunksize=chunksize, on_bad_lines='skip'):\n",
        "    # Extract features and labels from the current chunk\n",
        "    Passwords = chunk['password'].fillna('').astype(str)\n",
        "    Labels = chunk['strength']\n",
        "\n",
        "    # Vectorize the passwords in the chunk\n",
        "    Password_Vector = Vectorize.fit_transform(Passwords).toarray()\n",
        "\n",
        "    # Split the chunk into train/test sets\n",
        "    Input_Train, Input_Test, Output_Train, Output_Test = train_test_split(\n",
        "        Password_Vector, Labels, test_size=0.2, random_state=42\n",
        "    )\n",
        "\n",
        "    # Train the model on the current chunk\n",
        "    model.fit(Input_Train, Output_Train)\n",
        "\n",
        "\n",
        "\n",
        "joblib.dump(model, 'Password.joblib')\n",
        "joblib.dump(Vectorize, 'Vectorize.joblib')\n",
        "\n",
        "Prediction = model.predict(Input_Test)\n",
        "print(Prediction)\n",
        "\n",
        "Accuracy = accuracy_score(Output_Test, Prediction)\n",
        "print(f\"Accuracy: {Accuracy}\")\n"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Qy7D-trZ0v3",
        "outputId": "014bab78-12aa-4ec5-b1c1-37d4526c09c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1 1 1 ... 1 1 1]\n",
            "Accuracy: 0.8179460580912863\n"
          ]
        }
      ]
    },
    {
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import joblib\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "chunksize = 10000\n",
        "# Initialize RandomForestClassifier\n",
        "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "\n",
        "Vectorize = TfidfVectorizer(analyzer='char', ngram_range=(1,3), max_features=5000)\n",
        "\n",
        "for chunk in pd.read_csv('data.csv', chunksize=chunksize, on_bad_lines='skip'):\n",
        "    # Extract features and labels from the current chunk\n",
        "    Passwords = chunk['password'].fillna('').astype(str)\n",
        "    Labels = chunk['strength']\n",
        "\n",
        "    # Vectorize the passwords in the chunk\n",
        "    Password_Vector = Vectorize.fit_transform(Passwords).toarray()\n",
        "\n",
        "    # Split the chunk into train/test sets\n",
        "    Input_Train, Input_Test, Output_Train, Output_Test = train_test_split(\n",
        "        Password_Vector, Labels, test_size=0.2, random_state=42\n",
        "    )\n",
        "\n",
        "    # Train the model on the current chunk\n",
        "    model.fit(Input_Train, Output_Train)\n",
        "\n",
        "\n",
        "# Save the model and vectorizer\n",
        "joblib.dump(model, 'Password_RF.joblib')  # Save as a different file\n",
        "joblib.dump(Vectorize, 'Vectorize_RF.joblib') # Save as a different file\n",
        "\n",
        "# Make predictions and evaluate performance\n",
        "Prediction = model.predict(Input_Test)\n",
        "print(Prediction)\n",
        "\n",
        "Accuracy = accuracy_score(Output_Test, Prediction)\n",
        "print(f\"Accuracy: {Accuracy}\")"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VhsC0AH3cNrn",
        "outputId": "1a081593-d044-491f-a4e8-acdebab48ad1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1 1 1 ... 1 1 1]\n",
            "Accuracy: 0.8651452282157677\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "THis is anothe model\n"
      ],
      "metadata": {
        "id": "wKXedliCikY0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "import joblib\n",
        "\n",
        "chunksize = 10000\n",
        "sample_size = 50000\n",
        "test_size = 0.2\n",
        "\n",
        "\n",
        "# Step 1: Debugging - Check the sample data columns\n",
        "try:\n",
        "    sample_data = pd.read_csv('data.csv', nrows=sample_size, on_bad_lines='skip')\n",
        "    print(\"Columns in DataFrame:\", sample_data.columns)  # Debugging check\n",
        "    sample_data.columns = sample_data.columns.str.strip()  # Remove trailing/leading spaces\n",
        "    if 'password' not in sample_data.columns:\n",
        "        raise KeyError(\"'password' column does NOT exist in the data. Columns found are: \" + str(sample_data.columns))\n",
        "\n",
        "    # Ensure 'strength' column exists\n",
        "    if 'strength' not in sample_data.columns:\n",
        "        raise KeyError(\"'strength' column does NOT exist in the data. Columns found are: \" + str(sample_data.columns))\n",
        "\n",
        "    # Preprocess sample data\n",
        "    Passwords_sample = sample_data['password'].fillna('').astype(str)\n",
        "    Labels_sample = sample_data['strength'].astype(int)  # Ensure labels are integers\n",
        "except Exception as e:\n",
        "    print(f\"Error reading sample data: {e}\")\n",
        "    exit()\n",
        "\n",
        "\n",
        "# Initialize and fit vectorizer\n",
        "vectorizer = TfidfVectorizer(analyzer='char', ngram_range=(1, 3), max_features=5000)\n",
        "vectorizer.fit(Passwords_sample)\n",
        "joblib.dump(vectorizer, 'Vectorize_RF.joblib')\n",
        "\n",
        "# Split sample data for initial training and testing\n",
        "X_sample = vectorizer.transform(Passwords_sample)  # Vectorize the sample data\n",
        "Input_Train, Input_Test, Output_Train, Output_Test = train_test_split(\n",
        "    X_sample, Labels_sample, test_size=test_size, random_state=42\n",
        ")\n",
        "\n",
        "# Step 2: Initialize Incremental Model\n",
        "model = SGDClassifier(random_state=42, loss='log_loss')  # 'log' is the same as log_loss\n",
        "model.partial_fit(Input_Train, Output_Train, classes=[0, 1, 2])  # Pass all possible classes\n",
        "\n",
        "# Step 3: Process chunks incrementally and train the model\n",
        "try:\n",
        "    for chunk in pd.read_csv('data.csv', chunksize=chunksize, skiprows=sample_size, on_bad_lines='skip'):\n",
        "        # Debugging - Ensure the chunk contains expected columns\n",
        "        chunk.columns = chunk.columns.str.strip()  # Clean column names\n",
        "        if 'password' not in chunk.columns or 'strength' not in chunk.columns:\n",
        "            raise KeyError(\"Expected columns ('password', 'strength') are missing in chunk. Columns: \" + str(chunk.columns))\n",
        "\n",
        "        # Process each chunk\n",
        "        Passwords = chunk['password'].fillna('').astype(str)\n",
        "        Labels = chunk['strength'].astype(int)  # Ensure labels are integers\n",
        "\n",
        "        # Transform using the vectorizer\n",
        "        Password_Vector = vectorizer.transform(Passwords)\n",
        "\n",
        "        # Incrementally train the model\n",
        "        model.partial_fit(Password_Vector, Labels)\n",
        "except Exception as e:\n",
        "    print(f\"Error during incremental chunk training: {e}\")\n",
        "    exit()\n",
        "\n",
        "# Save the trained model\n",
        "joblib.dump(model, 'Password_RF.joblib')\n",
        "\n",
        "# Step 4: Evaluate the model\n",
        "try:\n",
        "    # Predict on the test set\n",
        "    Prediction = model.predict(Input_Test)\n",
        "    accuracy = accuracy_score(Output_Test, Prediction)\n",
        "    print(f\"Accuracy: {accuracy}\")\n",
        "    print(classification_report(Output_Test, Prediction))\n",
        "except Exception as e:\n",
        "    print(f\"Error during evaluation: {e}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hAfKD31Xqndl",
        "outputId": "5d026375-019d-4f2c-c873-1445fe8b7de4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Columns in DataFrame: Index(['password', 'strength'], dtype='object')\n",
            "Error during incremental chunk training: \"Expected columns ('password', 'strength') are missing in chunk. Columns: Index(['1portal', '0'], dtype='object')\"\n",
            "Accuracy: 0.8099\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.64      0.01      0.03      1397\n",
            "           1       0.80      0.99      0.89      7372\n",
            "           2       0.91      0.63      0.75      1231\n",
            "\n",
            "    accuracy                           0.81     10000\n",
            "   macro avg       0.79      0.55      0.55     10000\n",
            "weighted avg       0.79      0.81      0.75     10000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Random forest with only 100000 data"
      ],
      "metadata": {
        "id": "04VvV9lGsE76"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "import joblib\n",
        "\n",
        "# Constants\n",
        "num_rows_to_train = 140000  # Number of rows to train on\n",
        "Vectorize = TfidfVectorizer(analyzer='char', ngram_range=(1, 3), max_features=5000)\n",
        "\n",
        "# Read only the first 100,000 rows from the CSV\n",
        "data = pd.read_csv('data.csv', nrows=num_rows_to_train, on_bad_lines='skip')\n",
        "\n",
        "# Extract features and labels\n",
        "Passwords = data['password'].fillna('').astype(str)\n",
        "Labels = data['strength']\n",
        "\n",
        "Input_Train, Input_Test, Output_Train, Output_Test = train_test_split(\n",
        "    Passwords, Labels, test_size=0.3, random_state=42\n",
        ")\n",
        "\n",
        "# Vectorize the passwords\n",
        "Password_Vector = Vectorize.fit_transform(Input_Train).toarray()\n",
        "Test_Vector_input = Vectorize.transform(Input_Test).toarray()\n",
        "\n",
        "# Initialize RandomForestClassifier\n",
        "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "\n",
        "# Train the RandomForestClassifier on all 100,000 rows\n",
        "model.fit(Password_Vector, Output_Train)\n",
        "\n",
        "# Save the model and vectorizer\n",
        "joblib.dump(model, 'Password_RF.joblib')\n",
        "joblib.dump(Vectorize, 'Vectorize_RF.joblib')\n",
        "\n",
        "# Evaluate model predictions on training data itself (since no split is performed)\n",
        "Prediction = model.predict(Input_Test)\n",
        "accuracy = accuracy_score(Output_Test, Prediction)\n",
        "\n",
        "print(f\"Training accuracy (on the first 140,000 rows): {accuracy}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "unala7PrsI31",
        "outputId": "f623cc7d-0c44-4538-b059-5e978d5862df"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "could not convert string to float: 'tmsjga1969'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-ecfd51b359e5>\u001b[0m in \u001b[0;36m<cell line: 38>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;31m# Evaluate model predictions on training data itself (since no split is performed)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m \u001b[0mPrediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mInput_Test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mOutput_Test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPrediction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    902\u001b[0m             \u001b[0mThe\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    903\u001b[0m         \"\"\"\n\u001b[0;32m--> 904\u001b[0;31m         \u001b[0mproba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    905\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    906\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36mpredict_proba\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    944\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    945\u001b[0m         \u001b[0;31m# Check data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 946\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_X_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    947\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    948\u001b[0m         \u001b[0;31m# Assign chunk of trees to jobs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36m_validate_X_predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    639\u001b[0m             \u001b[0mforce_all_finite\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    640\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 641\u001b[0;31m         X = self._validate_data(\n\u001b[0m\u001b[1;32m    642\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    643\u001b[0m             \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDTYPE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[1;32m    631\u001b[0m                 \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    632\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mno_val_y\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 633\u001b[0;31m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"X\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    634\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mno_val_y\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    635\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m   1010\u001b[0m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1011\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1012\u001b[0;31m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_asarray_with_order\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mxp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1013\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcomplex_warning\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m                 raise ValueError(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/_array_api.py\u001b[0m in \u001b[0;36m_asarray_with_order\u001b[0;34m(array, dtype, order, copy, xp, device)\u001b[0m\n\u001b[1;32m    743\u001b[0m             \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    744\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 745\u001b[0;31m             \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    746\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    747\u001b[0m         \u001b[0;31m# At this point array is a NumPy ndarray. We convert it to an array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__array__\u001b[0;34m(self, dtype, copy)\u001b[0m\n\u001b[1;32m   1029\u001b[0m         \"\"\"\n\u001b[1;32m   1030\u001b[0m         \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1031\u001b[0;31m         \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1032\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0musing_copy_on_write\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mastype_is_view\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1033\u001b[0m             \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: could not convert string to float: 'tmsjga1969'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "data = pd.read_csv('data.csv', on_bad_lines='skip',nrows=140000)\n",
        "\n",
        "Passwords = data['password'].fillna('').astype(str)\n",
        "Lables = data['strength']\n",
        "\n",
        "Input_Train, Input_Test, Output_Train, Output_Test = train_test_split(\n",
        "    Passwords, Labels, test_size=0.05, random_state=42\n",
        ")\n",
        "\n",
        "\n",
        "# Load the saved model and vectorizer\n",
        "Model = joblib.load('Password_RF.joblib')\n",
        "Vectorize = joblib.load('Vectorize_RF.joblib')\n",
        "\n",
        "Input_Test = Vectorize.transform(Input_Test).toarray()\n",
        "\n",
        "Prediction = Model.predict(Input_Test)\n",
        "print(Prediction)\n",
        "\n",
        "Accuracy = accuracy_score(Output_Test, Prediction)\n",
        "print(f\"Accuracy: {Accuracy}\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QLS6_q1wjwgc",
        "outputId": "441b2f81-98f4-45f0-eae1-e0e680dc2740"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1 1 1 ... 1 0 1]\n",
            "Accuracy: 0.9192857142857143\n"
          ]
        }
      ]
    }
  ]
}